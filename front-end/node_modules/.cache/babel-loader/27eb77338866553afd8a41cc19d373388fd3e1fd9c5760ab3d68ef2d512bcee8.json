{"ast":null,"code":"var _s = $RefreshSig$();\nimport { MediaRecorder, register } from \"extendable-media-recorder\";\nimport { connect } from \"extendable-media-recorder-wav-encoder\";\nimport React from \"react\";\nimport { blobToBase64, stringify } from \"../utils\";\nimport { isSafari } from \"react-device-detect\";\nimport { Buffer } from \"buffer\";\nconst DEFAULT_CHUNK_SIZE = 2048;\nconst TIME_SLICE = 10;\nexport const useConversation = config => {\n  _s();\n  const [audioContext, setAudioContext] = React.useState();\n  const [audioAnalyser, setAudioAnalyser] = React.useState();\n  const [audioQueue, setAudioQueue] = React.useState([]);\n  const [processing, setProcessing] = React.useState(false);\n  const [recorder, setRecorder] = React.useState();\n  const [socket, setSocket] = React.useState();\n  const [status, setStatus] = React.useState(\"idle\");\n  const [error, setError] = React.useState();\n\n  // get audio context and metadata about user audio\n  React.useEffect(() => {\n    const audioContext = new AudioContext();\n    setAudioContext(audioContext);\n    const audioAnalyser = audioContext.createAnalyser();\n    setAudioAnalyser(audioAnalyser);\n  }, []);\n\n  // once the conversation is connected, stream the microphone audio into the socket\n  React.useEffect(() => {\n    if (!recorder || !socket) return;\n    if (status === \"connected\") {\n      recorder.addEventListener(\"dataavailable\", _ref => {\n        let {\n          data\n        } = _ref;\n        blobToBase64(data).then(base64Encoded => {\n          if (!base64Encoded) return;\n          const audioMessage = {\n            type: \"websocket_audio\",\n            data: base64Encoded\n          };\n          if (socket.readyState === WebSocket.OPEN) {\n            socket.send(stringify(audioMessage));\n          }\n        });\n      });\n    }\n  }, [recorder, socket, status]);\n\n  // accept wav audio from webpage\n  React.useEffect(() => {\n    const registerWav = async () => {\n      await register(await connect());\n    };\n    registerWav().catch(console.error);\n  }, []);\n\n  // play audio that is queued\n\n  React.useEffect(() => {\n    const playArrayBuffer = arrayBuffer => {\n      audioContext && audioAnalyser && audioContext.decodeAudioData(arrayBuffer, buffer => {\n        const source = audioContext.createBufferSource();\n        source.buffer = buffer;\n        source.connect(audioContext.destination);\n        source.connect(audioAnalyser);\n        source.start(0);\n        source.onended = () => {\n          setProcessing(false);\n        };\n      });\n    };\n    if (!processing && audioQueue.length > 0) {\n      setProcessing(true);\n      const audio = audioQueue.shift();\n      audio && fetch(URL.createObjectURL(new Blob([audio]))).then(response => response.arrayBuffer()).then(playArrayBuffer);\n    }\n  }, [audioQueue, processing]);\n  const stopConversation = error => {\n    setAudioQueue([]);\n    if (error) {\n      setError(error);\n      setStatus(\"error\");\n    } else {\n      setStatus(\"idle\");\n    }\n    if (!recorder || !socket) return;\n    recorder.stop();\n    const stopMessage = {\n      type: \"websocket_stop\"\n    };\n    socket.send(stringify(stopMessage));\n    socket.close();\n  };\n  const getBackendUrl = () => {\n    if (\"backendUrl\" in config) {\n      return config.backendUrl;\n    } else {\n      throw new Error(\"Invalid config\");\n    }\n  };\n  const getAudioConfigStartMessage = (inputAudioMetadata, outputAudioMetadata, chunkSize, downsampling, conversationId) => ({\n    type: \"websocket_audio_config_start\",\n    inputAudioConfig: {\n      samplingRate: inputAudioMetadata.samplingRate,\n      audioEncoding: inputAudioMetadata.audioEncoding,\n      chunkSize: chunkSize || DEFAULT_CHUNK_SIZE,\n      downsampling,\n      isSafari: isSafari\n    },\n    outputAudioConfig: {\n      samplingRate: outputAudioMetadata.samplingRate,\n      audioEncoding: outputAudioMetadata.audioEncoding\n    },\n    conversationId\n  });\n  const startConversation = async () => {\n    if (!audioContext || !audioAnalyser) return;\n    setStatus(\"connecting\");\n\n    // if (!isSafari && !isChrome) {\n    //   stopConversation(new Error(\"Unsupported browser\"));\n    //   return;\n    // }\n\n    if (audioContext.state === \"suspended\") {\n      audioContext.resume();\n    }\n    const backendUrl = getBackendUrl();\n    setError(undefined);\n    const socket = new WebSocket(backendUrl);\n    let error;\n    socket.onerror = event => {\n      console.error(event);\n      error = new Error(\"See console for error details\");\n    };\n    socket.onmessage = event => {\n      const message = JSON.parse(event.data);\n      if (message.type === \"websocket_audio\") {\n        setAudioQueue(prev => [...prev, Buffer.from(message.data, \"base64\")]);\n      } else if (message.type === \"websocket_ready\") {\n        setStatus(\"connected\");\n      }\n    };\n    socket.onclose = () => {\n      stopConversation(error);\n    };\n    setSocket(socket);\n\n    // wait for socket to be ready\n    await new Promise(resolve => {\n      const interval = setInterval(() => {\n        if (socket.readyState === WebSocket.OPEN) {\n          clearInterval(interval);\n          resolve(null);\n        }\n      }, 100);\n    });\n    let audioStream;\n    try {\n      const trackConstraints = {\n        echoCancellation: true\n      };\n      if (config.audioDeviceConfig.inputDeviceId) {\n        trackConstraints.deviceId = config.audioDeviceConfig.inputDeviceId;\n      }\n      audioStream = await navigator.mediaDevices.getUserMedia({\n        video: false,\n        audio: trackConstraints\n      });\n    } catch (error) {\n      if (error instanceof DOMException && error.name === \"NotAllowedError\") {\n        alert(\"Allowlist this site at chrome://settings/content/microphone to talk to the bot.\");\n        error = new Error(\"Microphone access denied\");\n      }\n      console.error(error);\n      stopConversation(error);\n      return;\n    }\n    const micSettings = audioStream.getAudioTracks()[0].getSettings();\n    const inputAudioMetadata = {\n      samplingRate: micSettings.sampleRate || audioContext.sampleRate,\n      audioEncoding: \"linear16\"\n    };\n    const outputAudioMetadata = {\n      samplingRate: config.audioDeviceConfig.outputSamplingRate || audioContext.sampleRate,\n      audioEncoding: \"linear16\"\n    };\n    const selfHostedConversationConfig = config;\n    const startMessage = getAudioConfigStartMessage(inputAudioMetadata, outputAudioMetadata, selfHostedConversationConfig.chunkSize, selfHostedConversationConfig.downsampling, selfHostedConversationConfig.conversationId);\n    socket.send(stringify(startMessage));\n    let recorderToUse = recorder;\n    if (recorderToUse && recorderToUse.state === \"paused\") {\n      recorderToUse.resume();\n    } else if (!recorderToUse) {\n      recorderToUse = new MediaRecorder(audioStream, {\n        mimeType: isSafari ? \"audio/mp4\" : \"audio/wav\"\n      });\n      setRecorder(recorderToUse);\n    }\n    if (recorderToUse.state === \"recording\") {\n      // When the recorder is in the recording state, see:\n      // https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/state\n      // which is not expected to call `start()` according to:\n      // https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/start.\n      return;\n    }\n    recorderToUse.start(TIME_SLICE);\n  };\n  return {\n    status,\n    start: startConversation,\n    stop: stopConversation,\n    error,\n    analyserNode: audioAnalyser\n  };\n};\n_s(useConversation, \"Ikenc5EFJzTr8K+qMcyzwFqp8Ac=\");","map":{"version":3,"names":["MediaRecorder","register","connect","React","blobToBase64","stringify","isSafari","Buffer","DEFAULT_CHUNK_SIZE","TIME_SLICE","useConversation","config","audioContext","setAudioContext","useState","audioAnalyser","setAudioAnalyser","audioQueue","setAudioQueue","processing","setProcessing","recorder","setRecorder","socket","setSocket","status","setStatus","error","setError","useEffect","AudioContext","createAnalyser","addEventListener","data","then","base64Encoded","audioMessage","type","readyState","WebSocket","OPEN","send","registerWav","catch","console","playArrayBuffer","arrayBuffer","decodeAudioData","buffer","source","createBufferSource","destination","start","onended","length","audio","shift","fetch","URL","createObjectURL","Blob","response","stopConversation","stop","stopMessage","close","getBackendUrl","backendUrl","Error","getAudioConfigStartMessage","inputAudioMetadata","outputAudioMetadata","chunkSize","downsampling","conversationId","inputAudioConfig","samplingRate","audioEncoding","outputAudioConfig","startConversation","state","resume","undefined","onerror","event","onmessage","message","JSON","parse","prev","from","onclose","Promise","resolve","interval","setInterval","clearInterval","audioStream","trackConstraints","echoCancellation","audioDeviceConfig","inputDeviceId","deviceId","navigator","mediaDevices","getUserMedia","video","DOMException","name","alert","micSettings","getAudioTracks","getSettings","sampleRate","outputSamplingRate","selfHostedConversationConfig","startMessage","recorderToUse","mimeType","analyserNode"],"sources":["D:/Nam_4/Thuc-tap-NCC/Chatbot-AIME/AIME/front-end/src/components/useConversation.ts"],"sourcesContent":["\r\nimport {\r\n  IMediaRecorder,\r\n  MediaRecorder,\r\n  register,\r\n} from \"extendable-media-recorder\";\r\nimport { connect } from \"extendable-media-recorder-wav-encoder\";\r\nimport React, { useEffect } from \"react\";\r\nimport {\r\n  ConversationConfig,\r\n  ConversationStatus,\r\n  SelfHostedConversationConfig,\r\n} from \"../types/conversation\";\r\nimport { blobToBase64, stringify } from \"../utils\";\r\nimport { AudioEncoding } from \"../types/vocode/audioEncoding\";\r\nimport {\r\n  AudioConfigStartMessage,\r\n  AudioMessage,\r\n  StartMessage,\r\n  StopMessage,\r\n} from \"../types/vocode/websocket\";\r\nimport { DeepgramTranscriberConfig, TranscriberConfig } from \"../types\";\r\nimport { isSafari, isChrome } from \"react-device-detect\";\r\nimport { Buffer } from \"buffer\";\r\n\r\nconst DEFAULT_CHUNK_SIZE = 2048;\r\nconst TIME_SLICE = 10;\r\n\r\nexport const useConversation = (\r\n  config: ConversationConfig | SelfHostedConversationConfig\r\n): {\r\n  status: ConversationStatus;\r\n  start: () => void;\r\n  stop: () => void;\r\n  error: Error | undefined;\r\n  analyserNode: AnalyserNode | undefined;\r\n} => {\r\n  const [audioContext, setAudioContext] = React.useState<AudioContext>();\r\n  const [audioAnalyser, setAudioAnalyser] = React.useState<AnalyserNode>();\r\n  const [audioQueue, setAudioQueue] = React.useState<Buffer[]>([]);\r\n  const [processing, setProcessing] = React.useState(false);\r\n  const [recorder, setRecorder] = React.useState<IMediaRecorder>();\r\n  const [socket, setSocket] = React.useState<WebSocket>();\r\n  const [status, setStatus] = React.useState<ConversationStatus>(\"idle\");\r\n  const [error, setError] = React.useState<Error>();\r\n\r\n  // get audio context and metadata about user audio\r\n  React.useEffect(() => {\r\n    const audioContext = new AudioContext();\r\n    setAudioContext(audioContext);\r\n    const audioAnalyser = audioContext.createAnalyser();\r\n    setAudioAnalyser(audioAnalyser);\r\n  }, []);\r\n\r\n  // once the conversation is connected, stream the microphone audio into the socket\r\n  React.useEffect(() => {\r\n    if (!recorder || !socket) return;\r\n    if (status === \"connected\") {\r\n      recorder.addEventListener(\"dataavailable\", ({ data }: { data: Blob }) => {\r\n        blobToBase64(data).then((base64Encoded: string | null) => {\r\n          \r\n          if (!base64Encoded) return;\r\n          const audioMessage: AudioMessage = {\r\n            type: \"websocket_audio\",\r\n            data: base64Encoded,\r\n          };\r\n\r\n          if(socket.readyState === WebSocket.OPEN) {\r\n            socket.send(stringify(audioMessage));\r\n          }\r\n        });\r\n      });\r\n    }\r\n  }, [recorder, socket, status]);\r\n\r\n  // accept wav audio from webpage\r\n  React.useEffect(() => {\r\n    const registerWav = async () => {\r\n      await register(await connect());\r\n    };\r\n    registerWav().catch(console.error);\r\n  }, []);\r\n\r\n  // play audio that is queued\r\n  \r\n  React.useEffect(() => {\r\n    const playArrayBuffer = (arrayBuffer: ArrayBuffer) => {\r\n      audioContext &&\r\n        audioAnalyser &&\r\n        audioContext.decodeAudioData(arrayBuffer, (buffer) => {\r\n          const source = audioContext.createBufferSource();\r\n          source.buffer = buffer;\r\n          source.connect(audioContext.destination);\r\n          source.connect(audioAnalyser);\r\n          source.start(0);\r\n          source.onended = () => {\r\n            setProcessing(false);\r\n          };\r\n        });\r\n    };\r\n    if (!processing && audioQueue.length > 0) {\r\n      setProcessing(true);\r\n      const audio = audioQueue.shift();\r\n\r\n      audio &&\r\n        fetch(URL.createObjectURL(new Blob([audio])))\r\n          .then((response) => response.arrayBuffer())\r\n          .then(playArrayBuffer);\r\n    }\r\n  }, [audioQueue, processing]);\r\n\r\n  const stopConversation = (error?: Error) => {\r\n    setAudioQueue([]);\r\n    if (error) {\r\n      setError(error);\r\n      setStatus(\"error\");\r\n    } else {\r\n      setStatus(\"idle\");\r\n    }\r\n    if (!recorder || !socket) return;\r\n    recorder.stop();\r\n    const stopMessage: StopMessage = {\r\n      type: \"websocket_stop\",\r\n    };\r\n    socket.send(stringify(stopMessage));\r\n    socket.close();\r\n  };\r\n\r\n  const getBackendUrl = () => {\r\n    if (\"backendUrl\" in config) {\r\n      return config.backendUrl;\r\n    } else {\r\n      throw new Error(\"Invalid config\");\r\n    }\r\n  };\r\n\r\n  const getAudioConfigStartMessage = (\r\n    inputAudioMetadata: { samplingRate: number; audioEncoding: AudioEncoding },\r\n    outputAudioMetadata: { samplingRate: number; audioEncoding: AudioEncoding },\r\n    chunkSize: number | undefined,\r\n    downsampling: number | undefined,\r\n    conversationId: string | undefined\r\n  ): AudioConfigStartMessage => ({\r\n    type: \"websocket_audio_config_start\",\r\n    inputAudioConfig: {\r\n      samplingRate: inputAudioMetadata.samplingRate,\r\n      audioEncoding: inputAudioMetadata.audioEncoding,\r\n      chunkSize: chunkSize || DEFAULT_CHUNK_SIZE,\r\n      downsampling,\r\n      isSafari: isSafari,\r\n    },\r\n    outputAudioConfig: {\r\n      samplingRate: outputAudioMetadata.samplingRate,\r\n      audioEncoding: outputAudioMetadata.audioEncoding,\r\n    },\r\n    conversationId,\r\n  });\r\n\r\n  const startConversation = async () => {\r\n    if (!audioContext || !audioAnalyser) return;\r\n    setStatus(\"connecting\");\r\n\r\n    // if (!isSafari && !isChrome) {\r\n    //   stopConversation(new Error(\"Unsupported browser\"));\r\n    //   return;\r\n    // }\r\n\r\n    if (audioContext.state === \"suspended\") {\r\n      audioContext.resume();\r\n    }\r\n\r\n    const backendUrl = getBackendUrl();\r\n\r\n    setError(undefined);\r\n    const socket = new WebSocket(backendUrl);\r\n    let error: Error | undefined;\r\n    socket.onerror = (event) => {\r\n      console.error(event);\r\n      error = new Error(\"See console for error details\");\r\n    };\r\n    socket.onmessage = (event) => {\r\n      const message = JSON.parse(event.data);\r\n      if (message.type === \"websocket_audio\") {\r\n        setAudioQueue((prev) => [...prev, Buffer.from(message.data, \"base64\")]);\r\n      } else if (message.type === \"websocket_ready\") {\r\n        setStatus(\"connected\");\r\n      }\r\n    };\r\n    socket.onclose = () => {\r\n      stopConversation(error);\r\n    };\r\n    setSocket(socket);\r\n\r\n    // wait for socket to be ready\r\n    await new Promise((resolve) => {\r\n      const interval = setInterval(() => {\r\n        if (socket.readyState === WebSocket.OPEN) {\r\n          clearInterval(interval);\r\n          resolve(null);\r\n        }\r\n      }, 100);\r\n    });\r\n\r\n    let audioStream;\r\n    try {\r\n      const trackConstraints: MediaTrackConstraints = {\r\n        echoCancellation: true,\r\n      };\r\n      if (config.audioDeviceConfig.inputDeviceId) {\r\n        trackConstraints.deviceId = config.audioDeviceConfig.inputDeviceId;\r\n      }\r\n      audioStream = await navigator.mediaDevices.getUserMedia({\r\n        video: false,\r\n        audio: trackConstraints,\r\n      });\r\n    } catch (error) {\r\n      if (error instanceof DOMException && error.name === \"NotAllowedError\") {\r\n        alert(\r\n          \"Allowlist this site at chrome://settings/content/microphone to talk to the bot.\"\r\n        );\r\n        error = new Error(\"Microphone access denied\");\r\n      }\r\n      console.error(error);\r\n      stopConversation(error as Error);\r\n      return;\r\n    }\r\n\r\n    const micSettings = audioStream.getAudioTracks()[0].getSettings();\r\n    const inputAudioMetadata = {\r\n      samplingRate: micSettings.sampleRate || audioContext.sampleRate,\r\n      audioEncoding: \"linear16\" as AudioEncoding,\r\n    };\r\n    const outputAudioMetadata = {\r\n      samplingRate:\r\n        config.audioDeviceConfig.outputSamplingRate || audioContext.sampleRate,\r\n      audioEncoding: \"linear16\" as AudioEncoding,\r\n    };\r\n\r\n    const selfHostedConversationConfig = config as SelfHostedConversationConfig;\r\n\r\n    const  startMessage = getAudioConfigStartMessage(\r\n        inputAudioMetadata,\r\n        outputAudioMetadata,\r\n        selfHostedConversationConfig.chunkSize,\r\n        selfHostedConversationConfig.downsampling,\r\n        selfHostedConversationConfig.conversationId\r\n      );\r\n\r\n    socket.send(stringify(startMessage));\r\n    \r\n    let recorderToUse = recorder;\r\n    if (recorderToUse && recorderToUse.state === \"paused\") {\r\n      recorderToUse.resume();\r\n    } else if (!recorderToUse) {\r\n      recorderToUse = new MediaRecorder(audioStream, {\r\n        mimeType: isSafari ? \"audio/mp4\" : \"audio/wav\",\r\n      });\r\n      \r\n      setRecorder(recorderToUse);\r\n    }\r\n\r\n    if (recorderToUse.state === \"recording\") {\r\n      // When the recorder is in the recording state, see:\r\n      // https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/state\r\n      // which is not expected to call `start()` according to:\r\n      // https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/start.\r\n      return;\r\n    } \r\n    recorderToUse.start(TIME_SLICE);\r\n  };\r\n\r\n  return {\r\n    status,\r\n    start: startConversation,\r\n    stop: stopConversation,\r\n    error,\r\n    analyserNode: audioAnalyser,\r\n  };\r\n};"],"mappings":";AACA,SAEEA,aAAa,EACbC,QAAQ,QACH,2BAA2B;AAClC,SAASC,OAAO,QAAQ,uCAAuC;AAC/D,OAAOC,KAAK,MAAqB,OAAO;AAMxC,SAASC,YAAY,EAAEC,SAAS,QAAQ,UAAU;AASlD,SAASC,QAAQ,QAAkB,qBAAqB;AACxD,SAASC,MAAM,QAAQ,QAAQ;AAE/B,MAAMC,kBAAkB,GAAG,IAAI;AAC/B,MAAMC,UAAU,GAAG,EAAE;AAErB,OAAO,MAAMC,eAAe,GAC1BC,MAAyD,IAOtD;EAAA;EACH,MAAM,CAACC,YAAY,EAAEC,eAAe,CAAC,GAAGV,KAAK,CAACW,QAAQ,EAAgB;EACtE,MAAM,CAACC,aAAa,EAAEC,gBAAgB,CAAC,GAAGb,KAAK,CAACW,QAAQ,EAAgB;EACxE,MAAM,CAACG,UAAU,EAAEC,aAAa,CAAC,GAAGf,KAAK,CAACW,QAAQ,CAAW,EAAE,CAAC;EAChE,MAAM,CAACK,UAAU,EAAEC,aAAa,CAAC,GAAGjB,KAAK,CAACW,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAM,CAACO,QAAQ,EAAEC,WAAW,CAAC,GAAGnB,KAAK,CAACW,QAAQ,EAAkB;EAChE,MAAM,CAACS,MAAM,EAAEC,SAAS,CAAC,GAAGrB,KAAK,CAACW,QAAQ,EAAa;EACvD,MAAM,CAACW,MAAM,EAAEC,SAAS,CAAC,GAAGvB,KAAK,CAACW,QAAQ,CAAqB,MAAM,CAAC;EACtE,MAAM,CAACa,KAAK,EAAEC,QAAQ,CAAC,GAAGzB,KAAK,CAACW,QAAQ,EAAS;;EAEjD;EACAX,KAAK,CAAC0B,SAAS,CAAC,MAAM;IACpB,MAAMjB,YAAY,GAAG,IAAIkB,YAAY,EAAE;IACvCjB,eAAe,CAACD,YAAY,CAAC;IAC7B,MAAMG,aAAa,GAAGH,YAAY,CAACmB,cAAc,EAAE;IACnDf,gBAAgB,CAACD,aAAa,CAAC;EACjC,CAAC,EAAE,EAAE,CAAC;;EAEN;EACAZ,KAAK,CAAC0B,SAAS,CAAC,MAAM;IACpB,IAAI,CAACR,QAAQ,IAAI,CAACE,MAAM,EAAE;IAC1B,IAAIE,MAAM,KAAK,WAAW,EAAE;MAC1BJ,QAAQ,CAACW,gBAAgB,CAAC,eAAe,EAAE,QAA8B;QAAA,IAA7B;UAAEC;QAAqB,CAAC;QAClE7B,YAAY,CAAC6B,IAAI,CAAC,CAACC,IAAI,CAAEC,aAA4B,IAAK;UAExD,IAAI,CAACA,aAAa,EAAE;UACpB,MAAMC,YAA0B,GAAG;YACjCC,IAAI,EAAE,iBAAiB;YACvBJ,IAAI,EAAEE;UACR,CAAC;UAED,IAAGZ,MAAM,CAACe,UAAU,KAAKC,SAAS,CAACC,IAAI,EAAE;YACvCjB,MAAM,CAACkB,IAAI,CAACpC,SAAS,CAAC+B,YAAY,CAAC,CAAC;UACtC;QACF,CAAC,CAAC;MACJ,CAAC,CAAC;IACJ;EACF,CAAC,EAAE,CAACf,QAAQ,EAAEE,MAAM,EAAEE,MAAM,CAAC,CAAC;;EAE9B;EACAtB,KAAK,CAAC0B,SAAS,CAAC,MAAM;IACpB,MAAMa,WAAW,GAAG,YAAY;MAC9B,MAAMzC,QAAQ,CAAC,MAAMC,OAAO,EAAE,CAAC;IACjC,CAAC;IACDwC,WAAW,EAAE,CAACC,KAAK,CAACC,OAAO,CAACjB,KAAK,CAAC;EACpC,CAAC,EAAE,EAAE,CAAC;;EAEN;;EAEAxB,KAAK,CAAC0B,SAAS,CAAC,MAAM;IACpB,MAAMgB,eAAe,GAAIC,WAAwB,IAAK;MACpDlC,YAAY,IACVG,aAAa,IACbH,YAAY,CAACmC,eAAe,CAACD,WAAW,EAAGE,MAAM,IAAK;QACpD,MAAMC,MAAM,GAAGrC,YAAY,CAACsC,kBAAkB,EAAE;QAChDD,MAAM,CAACD,MAAM,GAAGA,MAAM;QACtBC,MAAM,CAAC/C,OAAO,CAACU,YAAY,CAACuC,WAAW,CAAC;QACxCF,MAAM,CAAC/C,OAAO,CAACa,aAAa,CAAC;QAC7BkC,MAAM,CAACG,KAAK,CAAC,CAAC,CAAC;QACfH,MAAM,CAACI,OAAO,GAAG,MAAM;UACrBjC,aAAa,CAAC,KAAK,CAAC;QACtB,CAAC;MACH,CAAC,CAAC;IACN,CAAC;IACD,IAAI,CAACD,UAAU,IAAIF,UAAU,CAACqC,MAAM,GAAG,CAAC,EAAE;MACxClC,aAAa,CAAC,IAAI,CAAC;MACnB,MAAMmC,KAAK,GAAGtC,UAAU,CAACuC,KAAK,EAAE;MAEhCD,KAAK,IACHE,KAAK,CAACC,GAAG,CAACC,eAAe,CAAC,IAAIC,IAAI,CAAC,CAACL,KAAK,CAAC,CAAC,CAAC,CAAC,CAC1CrB,IAAI,CAAE2B,QAAQ,IAAKA,QAAQ,CAACf,WAAW,EAAE,CAAC,CAC1CZ,IAAI,CAACW,eAAe,CAAC;IAC5B;EACF,CAAC,EAAE,CAAC5B,UAAU,EAAEE,UAAU,CAAC,CAAC;EAE5B,MAAM2C,gBAAgB,GAAInC,KAAa,IAAK;IAC1CT,aAAa,CAAC,EAAE,CAAC;IACjB,IAAIS,KAAK,EAAE;MACTC,QAAQ,CAACD,KAAK,CAAC;MACfD,SAAS,CAAC,OAAO,CAAC;IACpB,CAAC,MAAM;MACLA,SAAS,CAAC,MAAM,CAAC;IACnB;IACA,IAAI,CAACL,QAAQ,IAAI,CAACE,MAAM,EAAE;IAC1BF,QAAQ,CAAC0C,IAAI,EAAE;IACf,MAAMC,WAAwB,GAAG;MAC/B3B,IAAI,EAAE;IACR,CAAC;IACDd,MAAM,CAACkB,IAAI,CAACpC,SAAS,CAAC2D,WAAW,CAAC,CAAC;IACnCzC,MAAM,CAAC0C,KAAK,EAAE;EAChB,CAAC;EAED,MAAMC,aAAa,GAAG,MAAM;IAC1B,IAAI,YAAY,IAAIvD,MAAM,EAAE;MAC1B,OAAOA,MAAM,CAACwD,UAAU;IAC1B,CAAC,MAAM;MACL,MAAM,IAAIC,KAAK,CAAC,gBAAgB,CAAC;IACnC;EACF,CAAC;EAED,MAAMC,0BAA0B,GAAG,CACjCC,kBAA0E,EAC1EC,mBAA2E,EAC3EC,SAA6B,EAC7BC,YAAgC,EAChCC,cAAkC,MACL;IAC7BrC,IAAI,EAAE,8BAA8B;IACpCsC,gBAAgB,EAAE;MAChBC,YAAY,EAAEN,kBAAkB,CAACM,YAAY;MAC7CC,aAAa,EAAEP,kBAAkB,CAACO,aAAa;MAC/CL,SAAS,EAAEA,SAAS,IAAIhE,kBAAkB;MAC1CiE,YAAY;MACZnE,QAAQ,EAAEA;IACZ,CAAC;IACDwE,iBAAiB,EAAE;MACjBF,YAAY,EAAEL,mBAAmB,CAACK,YAAY;MAC9CC,aAAa,EAAEN,mBAAmB,CAACM;IACrC,CAAC;IACDH;EACF,CAAC,CAAC;EAEF,MAAMK,iBAAiB,GAAG,YAAY;IACpC,IAAI,CAACnE,YAAY,IAAI,CAACG,aAAa,EAAE;IACrCW,SAAS,CAAC,YAAY,CAAC;;IAEvB;IACA;IACA;IACA;;IAEA,IAAId,YAAY,CAACoE,KAAK,KAAK,WAAW,EAAE;MACtCpE,YAAY,CAACqE,MAAM,EAAE;IACvB;IAEA,MAAMd,UAAU,GAAGD,aAAa,EAAE;IAElCtC,QAAQ,CAACsD,SAAS,CAAC;IACnB,MAAM3D,MAAM,GAAG,IAAIgB,SAAS,CAAC4B,UAAU,CAAC;IACxC,IAAIxC,KAAwB;IAC5BJ,MAAM,CAAC4D,OAAO,GAAIC,KAAK,IAAK;MAC1BxC,OAAO,CAACjB,KAAK,CAACyD,KAAK,CAAC;MACpBzD,KAAK,GAAG,IAAIyC,KAAK,CAAC,+BAA+B,CAAC;IACpD,CAAC;IACD7C,MAAM,CAAC8D,SAAS,GAAID,KAAK,IAAK;MAC5B,MAAME,OAAO,GAAGC,IAAI,CAACC,KAAK,CAACJ,KAAK,CAACnD,IAAI,CAAC;MACtC,IAAIqD,OAAO,CAACjD,IAAI,KAAK,iBAAiB,EAAE;QACtCnB,aAAa,CAAEuE,IAAI,IAAK,CAAC,GAAGA,IAAI,EAAElF,MAAM,CAACmF,IAAI,CAACJ,OAAO,CAACrD,IAAI,EAAE,QAAQ,CAAC,CAAC,CAAC;MACzE,CAAC,MAAM,IAAIqD,OAAO,CAACjD,IAAI,KAAK,iBAAiB,EAAE;QAC7CX,SAAS,CAAC,WAAW,CAAC;MACxB;IACF,CAAC;IACDH,MAAM,CAACoE,OAAO,GAAG,MAAM;MACrB7B,gBAAgB,CAACnC,KAAK,CAAC;IACzB,CAAC;IACDH,SAAS,CAACD,MAAM,CAAC;;IAEjB;IACA,MAAM,IAAIqE,OAAO,CAAEC,OAAO,IAAK;MAC7B,MAAMC,QAAQ,GAAGC,WAAW,CAAC,MAAM;QACjC,IAAIxE,MAAM,CAACe,UAAU,KAAKC,SAAS,CAACC,IAAI,EAAE;UACxCwD,aAAa,CAACF,QAAQ,CAAC;UACvBD,OAAO,CAAC,IAAI,CAAC;QACf;MACF,CAAC,EAAE,GAAG,CAAC;IACT,CAAC,CAAC;IAEF,IAAII,WAAW;IACf,IAAI;MACF,MAAMC,gBAAuC,GAAG;QAC9CC,gBAAgB,EAAE;MACpB,CAAC;MACD,IAAIxF,MAAM,CAACyF,iBAAiB,CAACC,aAAa,EAAE;QAC1CH,gBAAgB,CAACI,QAAQ,GAAG3F,MAAM,CAACyF,iBAAiB,CAACC,aAAa;MACpE;MACAJ,WAAW,GAAG,MAAMM,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QACtDC,KAAK,EAAE,KAAK;QACZnD,KAAK,EAAE2C;MACT,CAAC,CAAC;IACJ,CAAC,CAAC,OAAOvE,KAAK,EAAE;MACd,IAAIA,KAAK,YAAYgF,YAAY,IAAIhF,KAAK,CAACiF,IAAI,KAAK,iBAAiB,EAAE;QACrEC,KAAK,CACH,iFAAiF,CAClF;QACDlF,KAAK,GAAG,IAAIyC,KAAK,CAAC,0BAA0B,CAAC;MAC/C;MACAxB,OAAO,CAACjB,KAAK,CAACA,KAAK,CAAC;MACpBmC,gBAAgB,CAACnC,KAAK,CAAU;MAChC;IACF;IAEA,MAAMmF,WAAW,GAAGb,WAAW,CAACc,cAAc,EAAE,CAAC,CAAC,CAAC,CAACC,WAAW,EAAE;IACjE,MAAM1C,kBAAkB,GAAG;MACzBM,YAAY,EAAEkC,WAAW,CAACG,UAAU,IAAIrG,YAAY,CAACqG,UAAU;MAC/DpC,aAAa,EAAE;IACjB,CAAC;IACD,MAAMN,mBAAmB,GAAG;MAC1BK,YAAY,EACVjE,MAAM,CAACyF,iBAAiB,CAACc,kBAAkB,IAAItG,YAAY,CAACqG,UAAU;MACxEpC,aAAa,EAAE;IACjB,CAAC;IAED,MAAMsC,4BAA4B,GAAGxG,MAAsC;IAE3E,MAAOyG,YAAY,GAAG/C,0BAA0B,CAC5CC,kBAAkB,EAClBC,mBAAmB,EACnB4C,4BAA4B,CAAC3C,SAAS,EACtC2C,4BAA4B,CAAC1C,YAAY,EACzC0C,4BAA4B,CAACzC,cAAc,CAC5C;IAEHnD,MAAM,CAACkB,IAAI,CAACpC,SAAS,CAAC+G,YAAY,CAAC,CAAC;IAEpC,IAAIC,aAAa,GAAGhG,QAAQ;IAC5B,IAAIgG,aAAa,IAAIA,aAAa,CAACrC,KAAK,KAAK,QAAQ,EAAE;MACrDqC,aAAa,CAACpC,MAAM,EAAE;IACxB,CAAC,MAAM,IAAI,CAACoC,aAAa,EAAE;MACzBA,aAAa,GAAG,IAAIrH,aAAa,CAACiG,WAAW,EAAE;QAC7CqB,QAAQ,EAAEhH,QAAQ,GAAG,WAAW,GAAG;MACrC,CAAC,CAAC;MAEFgB,WAAW,CAAC+F,aAAa,CAAC;IAC5B;IAEA,IAAIA,aAAa,CAACrC,KAAK,KAAK,WAAW,EAAE;MACvC;MACA;MACA;MACA;MACA;IACF;IACAqC,aAAa,CAACjE,KAAK,CAAC3C,UAAU,CAAC;EACjC,CAAC;EAED,OAAO;IACLgB,MAAM;IACN2B,KAAK,EAAE2B,iBAAiB;IACxBhB,IAAI,EAAED,gBAAgB;IACtBnC,KAAK;IACL4F,YAAY,EAAExG;EAChB,CAAC;AACH,CAAC;AAAC,GA1PWL,eAAe"},"metadata":{},"sourceType":"module","externalDependencies":[]}